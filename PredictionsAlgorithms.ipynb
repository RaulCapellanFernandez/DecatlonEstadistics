{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3: Estudio de diferentes algoritmos de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook vamos a aplicar diferentes algoritmos para estudiar su efectividad para este problema e intentaremos predicciones para los Juegos Olímpicos de 2021.\n",
    "\n",
    "Los algoritmos que se aplican son: \n",
    "* Matriz de confusión\n",
    "* Datos de entrenamiento y datos de test\n",
    "* Knn - Vecinos cercanos\n",
    "* Regresión Lineal\n",
    "* Regresión Logística\n",
    "* Naive Bayes\n",
    "* Gaussian Naive Bayes\n",
    "* K-means\n",
    "* Perceptron\n",
    "* MLP - Multi layer perceptron\n",
    "* Decision Tree\n",
    "* SVM - Supervised Vector Machine\n",
    "* Descenso del gradiente\n",
    "* Random Forest\n",
    "* ¿¿RED NEURONAL??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from numpy import * \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "#confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "#print(confusion_matrix)\n",
    "#from sklearn.metrics import classification_report\n",
    "#print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lee el excel generado en el otro documento .ipynb\n",
    "ddbb=pd.read_excel(\"/Github/DecatlonEstadistics/resources/data.xlsx\")\n",
    "del ddbb['1500m NF']\n",
    "\n",
    "ddbb['Country']=ddbb['Country'].str.lower()\n",
    "\n",
    "ddbb.columns = ['Position', 'Athlete', 'Age', 'Country', 'Total Points', 'Year', 'Competition', '100m', \n",
    "                 '100m Points', 'Lj', 'Lj Points', 'Sp', 'Sp Points', 'Hj', 'Hj Points', '400m', '400m Points', \n",
    "                 '110m H', '110m H Points', 'Dt', 'Dt Points', 'Pv', 'Pv Points', 'Jt', 'Jt Points', \n",
    "                 '1500m Points', '1500m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrizConfusion(y_test, y_pred):\n",
    "    Tp = 0\n",
    "    Tn = 0\n",
    "    Fp = 0\n",
    "    Fn = 0\n",
    "    \n",
    "    #Crea una matriz de confusion para cada una de las posibles posiciones\n",
    "    matrizConfusion = multilabel_confusion_matrix(y_test, y_pred,labels=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,\n",
    "                                                    22,23,24,25,26,27,28,29,30,31,32,33,34])\n",
    "    \n",
    "    #Hace una media de todas las matrices de cada posicion para comparar con los diferentes algoritmos\n",
    "    for i in range(len(matrizConfusion)):\n",
    "        Tp = Tp + matrizConfusion[i][0][0] #True Positive\n",
    "        Fp = Fp + matrizConfusion[i][0][1] #False Positive\n",
    "        Fn = Fn + matrizConfusion[i][1][0] #False Negative\n",
    "        Tn = Tn + matrizConfusion[i][1][1] #True Negative\n",
    "\n",
    "    Tp = Tp/len(matrizConfusion)\n",
    "    Fp = Fp/len(matrizConfusion)\n",
    "    Fn = Fn/len(matrizConfusion)\n",
    "    Tn = Tn/len(matrizConfusion)\n",
    "    \n",
    "    #Con esos datos hago la matriz de posicion\n",
    "    matriz = [[Tp, Fp], [Fn, Tn]]\n",
    "    \n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datos de entrenamiento y datos de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se entrenan en función a todas las pruebas resultantes y se clasifican en función a la posición obtenida.\n",
    "El 70% de los datos se utilizan para entrenamiento.\n",
    "El 30% restante se utiliza para tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddbbData = ddbb[['100m','100m Points','Lj','Lj Points','Sp','Sp Points','Hj','Hj Points','400m Points','400m',\n",
    "                 '110m H','110m H Points','Dt','Dt Points','Pv','Pv Points','Jt','Jt Points','1500m Points','1500m']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ddbbData, ddbb['Position'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vecinos Cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Vecinos cercanos es: 0.082\n",
      "0.9460207612456748\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Entrena el modelo\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predice para los datos de test\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print('El accuracy en Vecinos cercanos es: {:.3f}'.format(knn.score(X_test, y_test)))\n",
    "m = matrizConfusion(y_test, y_pred)\n",
    "\n",
    "dividendo= m[0][0]+m[1][1]\n",
    "total= m[0][0]+m[0][1]+m[1][0]+m[1][1]\n",
    "\n",
    "print(dividendo/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Regresión Linear es: 0.437\n"
     ]
    }
   ],
   "source": [
    "regL = linear_model.LinearRegression()\n",
    "\n",
    "regL.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regL.predict(X_test)\n",
    "\n",
    "print('El accuracy en Regresión Linear es: {:.3f}'.format(regL.score(X_test, y_test)))\n",
    "#matrizConfusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Regresión Logistica es:: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[240.52941176470588, 6.970588235294118],\n",
       " [6.970588235294118, 0.5294117647058824]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(random_state=0)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('El accuracy en Regresión Logistica es:: {:.3f}'.format(logreg.score(X_test, y_test)))\n",
    "matrizConfusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Naive Bayes es:: 0.059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[240.44117647058823, 7.0588235294117645],\n",
       " [7.0588235294117645, 0.4411764705882353]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "print('El accuracy en Naive Bayes es:: {:.3f}'.format(gnb.score(X_test, y_test)))\n",
    "matrizConfusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5).fit(ddbbData)\n",
    "centroids = kmeans.cluster_centers_\n",
    "#print(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Perceptron es:: 0.024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[240.1764705882353, 7.323529411764706],\n",
       " [7.323529411764706, 0.17647058823529413]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percep = Perceptron(tol=1e-5, random_state=1)\n",
    "\n",
    "percep.fit(X_train, y_train)\n",
    "\n",
    "y_pred = percep.predict(X_test)\n",
    "\n",
    "print('El accuracy en Perceptron es:: {:.3f}'.format(percep.score(X_test, y_test)))\n",
    "matrizConfusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MLP- Perceptron Multi Capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en MLP es:: 0.027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[240.2058823529412, 7.294117647058823],\n",
       " [7.294117647058823, 0.20588235294117646]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print('El accuracy en MLP es:: {:.3f}'.format(mlp.score(X_test, y_test)))\n",
    "matrizConfusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SVM - Supervised Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en SVM es:: 0.090\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('El accuracy en SVM es:: {:.3f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Descenso del gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Descenso del gradiente es:: 0.051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[240.38235294117646, 7.117647058823529],\n",
       " [7.117647058823529, 0.38235294117647056]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dGrad = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "\n",
    "dGrad.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dGrad.predict(X_test)\n",
    "\n",
    "print('El accuracy en Descenso del gradiente es:: {:.3f}'.format(dGrad.score(X_test, y_test)))\n",
    "matrizConfusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Arbol de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en arboles de decision es:: 0.082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[240.61764705882354, 6.882352941176471],\n",
       " [6.882352941176471, 0.6176470588235294]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('El accuracy en arboles de decision es:: {:.3f}'.format(clf.score(X_test, y_test)))\n",
    "matrizConfusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en random forest es:: 0.082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[240.6764705882353, 6.823529411764706],\n",
       " [6.823529411764706, 0.6764705882352942]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rForest=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rForest.fit(X_train,y_train)\n",
    "\n",
    "y_pred=rForest.predict(X_test)\n",
    "print('El accuracy en random forest es:: {:.3f}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "matrizConfusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
