{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3: Estudio de diferentes algoritmos de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook vamos a aplicar diferentes algoritmos para estudiar su efectividad para este problema e intentaremos predicciones para los Juegos Olímpicos de 2021.\n",
    "\n",
    "Los algoritmos que se aplican son: \n",
    "* Datos de entrenamiento y datos de test\n",
    "* Knn - Vecinos cercanos\n",
    "* Regresión Lineal\n",
    "* Regresión Logística\n",
    "* Naive Bayes\n",
    "* Gaussian Naive Bayes\n",
    "* K-means\n",
    "* Perceptron\n",
    "* MLP - Multi layer perceptron\n",
    "* Curva ROC\n",
    "* Decision Tree\n",
    "* SVM - Supervised Vector Machine\n",
    "* Descenso del gradiente\n",
    "* Random Forest\n",
    "* ¿¿RED NEURONAL??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from numpy import * \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "#confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "#print(confusion_matrix)\n",
    "#from sklearn.metrics import classification_report\n",
    "#print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lee el excel generado en el otro documento .ipynb\n",
    "ddbb=pd.read_excel(\"/Github/DecatlonEstadistics/resources/data.xlsx\")\n",
    "del ddbb['1500m NF']\n",
    "\n",
    "ddbb['Country']=ddbb['Country'].str.lower()\n",
    "\n",
    "ddbb.columns = ['Position', 'Athlete', 'Age', 'Country', 'Total Points', 'Year', 'Competition', '100m', \n",
    "                 '100m Points', 'Lj', 'Lj Points', 'Sp', 'Sp Points', 'Hj', 'Hj Points', '400m', '400m Points', \n",
    "                 '110m H', '110m H Points', 'Dt', 'Dt Points', 'Pv', 'Pv Points', 'Jt', 'Jt Points', \n",
    "                 '1500m Points', '1500m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datos de entrenamiento y datos de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se entrenan en función a todas las pruebas resultantes y se clasifican en función a la posición obtenida.\n",
    "El 70% de los datos se utilizan para entrenamiento.\n",
    "El 30% restante se utiliza para tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddbbData = ddbb[['100m','100m Points','Lj','Lj Points','Sp','Sp Points','Hj','Hj Points','400m Points','400m',\n",
    "                 '110m H','110m H Points','Dt','Dt Points','Pv','Pv Points','Jt','Jt Points','1500m Points','1500m']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ddbbData, ddbb['Position'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vecinos Cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[222  25]\n",
      "  [  1   7]]\n",
      "\n",
      " [[229  18]\n",
      "  [  7   1]]\n",
      "\n",
      " [[219  20]\n",
      "  [ 15   1]]\n",
      "\n",
      " [[226  17]\n",
      "  [ 10   2]]\n",
      "\n",
      " [[225  17]\n",
      "  [ 12   1]]\n",
      "\n",
      " [[226  20]\n",
      "  [  8   1]]\n",
      "\n",
      " [[237   9]\n",
      "  [  9   0]]\n",
      "\n",
      " [[232  16]\n",
      "  [  7   0]]\n",
      "\n",
      " [[224  22]\n",
      "  [  9   0]]\n",
      "\n",
      " [[230  12]\n",
      "  [ 13   0]]\n",
      "\n",
      " [[231  10]\n",
      "  [ 12   2]]\n",
      "\n",
      " [[234   7]\n",
      "  [ 14   0]]\n",
      "\n",
      " [[242   6]\n",
      "  [  7   0]]\n",
      "\n",
      " [[241   0]\n",
      "  [ 13   1]]\n",
      "\n",
      " [[238   1]\n",
      "  [ 16   0]]\n",
      "\n",
      " [[232  10]\n",
      "  [ 13   0]]\n",
      "\n",
      " [[237   9]\n",
      "  [  9   0]]\n",
      "\n",
      " [[245   0]\n",
      "  [ 10   0]]\n",
      "\n",
      " [[245   2]\n",
      "  [  8   0]]\n",
      "\n",
      " [[242   4]\n",
      "  [  9   0]]\n",
      "\n",
      " [[250   0]\n",
      "  [  5   0]]\n",
      "\n",
      " [[242   6]\n",
      "  [  7   0]]\n",
      "\n",
      " [[245   5]\n",
      "  [  5   0]]\n",
      "\n",
      " [[250   1]\n",
      "  [  4   0]]\n",
      "\n",
      " [[251   0]\n",
      "  [  4   0]]\n",
      "\n",
      " [[253   0]\n",
      "  [  2   0]]\n",
      "\n",
      " [[254   0]\n",
      "  [  1   0]]\n",
      "\n",
      " [[252   2]\n",
      "  [  1   0]]\n",
      "\n",
      " [[254   0]\n",
      "  [  1   0]]\n",
      "\n",
      " [[253   0]\n",
      "  [  2   0]]\n",
      "\n",
      " [[253   0]\n",
      "  [  2   0]]\n",
      "\n",
      " [[253   0]\n",
      "  [  2   0]]\n",
      "\n",
      " [[254   0]\n",
      "  [  1   0]]\n",
      "\n",
      " [[255   0]\n",
      "  [  0   0]]]\n",
      "El accuracy en Vecinos Cercanos es: 0.063\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Entrena el modelo\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predice para los datos de test\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "matrizConfusion = multilabel_confusion_matrix(y_test, y_pred,labels=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,\n",
    "                                                    22,23,24,25,26,27,28,29,30,31,32,33,34])\n",
    " \n",
    "print(pene)\n",
    "    \n",
    "print('El accuracy en Vecinos Cercanos es: {:.3f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Regresión Linear es: 0.485\n"
     ]
    }
   ],
   "source": [
    "regL = linear_model.LinearRegression()\n",
    "\n",
    "regL.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regL.predict(X_test)\n",
    "\n",
    "print('El accuracy en Regresión Linear es: {:.3f}'.format(regL.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Regresión Logistica es:: 0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(random_state=0)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('El accuracy en Regresión Logistica es:: {:.3f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Naive Bayes es:: 0.059\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "print('El accuracy en Naive Bayes es:: {:.3f}'.format(gnb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.15503670e+01 7.10403670e+02 6.54231651e+00 7.06518849e+02\n",
      "  1.21625688e+01 6.16591743e+02 1.75802752e+00 5.94348624e+02\n",
      "  6.97288991e+02 5.26285780e+01 1.63089908e+01 6.50724972e+02\n",
      "  3.65132110e+01 5.91853211e+02 3.16000000e+00 4.08968550e+02\n",
      "  4.98710321e+01 5.87720183e+02 5.85619266e+02 2.86856321e+02]\n",
      " [1.10037480e+01 8.59363285e+02 7.25082935e+00 8.58912069e+02\n",
      "  1.43604466e+01 7.51174450e+02 1.98925040e+00 7.94833078e+02\n",
      "  8.54498262e+02 4.90530463e+01 1.46562998e+01 8.83336638e+02\n",
      "  4.41049761e+01 7.49105423e+02 4.72647528e+00 8.28708182e+02\n",
      "  6.01726954e+01 7.37621743e+02 6.93311802e+02 2.77283043e+02]\n",
      " [1.13350000e+01 7.76000000e+02 6.68000000e+00 7.39000000e+02\n",
      "  1.29150000e+01 6.62500000e+02 1.87000000e+00 6.88000000e+02\n",
      "  8.12000000e+02 5.00750000e+01 1.57050000e+01 7.67500000e+02\n",
      "  3.80400000e+03 6.25000000e+02 3.85000000e+00 5.79500000e+02\n",
      "  5.46800000e+01 6.58000000e+02 6.77000000e+02 2.80800000e+02]\n",
      " [1.11800000e+01 8.21000000e+02 6.88000000e+02 7.85000000e+02\n",
      "  1.37200000e+03 7.11000000e+02 1.93000000e+02 7.40000000e+02\n",
      "  5.06000000e+01 7.87000000e+02 1.62500000e+01 7.05000000e+02\n",
      "  4.77100000e+03 8.23000000e+02 0.00000000e+00 0.00000000e+00\n",
      "  5.51100000e+03 6.65000000e+02 4.49000000e+02 3.20260000e+02]\n",
      " [1.08550000e+01 8.93500000e+02 7.11500000e+00 8.41500000e+02\n",
      "  1.39000000e+01 7.22500000e+02 2.02500000e+00 8.26500000e+02\n",
      "  8.33500000e+02 4.95950000e+03 1.57700000e+01 7.64000000e+02\n",
      "  4.50300000e+01 7.67500000e+02 4.65000000e+00 8.04500000e+02\n",
      "  5.95200000e+01 7.30500000e+02 6.65500000e+02 2.83100000e+02]]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5).fit(ddbbData)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en Perceptron es:: 0.067\n"
     ]
    }
   ],
   "source": [
    "percep = Perceptron(tol=1e-5, random_state=1)\n",
    "\n",
    "percep.fit(X_train, y_train)\n",
    "\n",
    "y_pred = percep.predict(X_test)\n",
    "\n",
    "print('El accuracy en Perceptron es:: {:.3f}'.format(percep.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MLP- Perceptron Multi Capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en MLP es:: 0.031\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print('El accuracy en MLP es:: {:.3f}'.format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SVM - Supervised Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('El accuracy en SVM es:: {:.3f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Descenso del gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dGrad = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "\n",
    "dGrad.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dGrad.predict(X_test)\n",
    "\n",
    "print('El accuracy en Descenso del gradiente es:: {:.3f}'.format(dGrad.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Arbol de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('El accuracy en SVM es:: {:.3f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rForest=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rForest.fit(X_train,y_train)\n",
    "\n",
    "y_pred=rForest.predict(X_test)\n",
    "\n",
    "print('El accuracy en Random Forest es:: {:.3f}'.format(rForest.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
